import numpy as np
from numpy import random
from game import Game

class Full_Information_Game(Game):
    def __init__(self, data_generating_mechanism, bandit_algorithm):
        super().__init__(data_generating_mechanism, bandit_algorithm)
        
    def simulate_one_run(self):
       history = np.zeros(shape = (self.data_generating_mechanism.get_K(), 
                                   self.data_generating_mechanism.get_T()))
       current_loss = np.zeros(shape = self.data_generating_mechanism.get_T())
       regret = np.zeros(shape = self.data_generating_mechanism.get_T())
       
       for t in range(1, self.data_generating_mechanism.get_T() + 1):
            # estimate arm values 
            I_t = self.bandit_algorithm.get_arm_to_pull(history, t)

            # reward is  
            # generated by
            # nature
            r_t = self.data_generating_mechanism.get_rewards(t)

            # Update the statistics
            for i in range(self.data_generating_mechanism.get_K()): 
                history[i][t-1] = 1 - r_t[i]
            
            current_loss[t-1] = 1 - r_t[I_t]
            
       cumulative_losses = np.sum(history, axis=1)
       optimal_arm = np.argmin(cumulative_losses)

       for t in range(self.data_generating_mechanism.get_T()):
        if (t == 0):
            regret[t] = current_loss[t] - history[optimal_arm][t]
        else: 
            regret[t] = regret[t-1] + (current_loss[t] - history[optimal_arm][t])

       return regret


        